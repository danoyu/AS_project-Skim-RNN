{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importer données rotten tomatoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pickle as pkl\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "#load RottenTomatoes sentiment analysis dataset\n",
    "def load_tsv(filename):\n",
    "    phID, stcID, ph, sentiment = [],[],[],[]\n",
    "    with open(filename) as f: \n",
    "        l = f.readline()\n",
    "        if (len(l.split(\"\\t\")) == 4):\n",
    "            '''TRAIN dataset'''\n",
    "            for line in f:\n",
    "                l = line.split(\"\\t\")\n",
    "                if (int(l[3][0]) < 2):\n",
    "                    phID.append(l[0]), stcID.append(l[1]), ph.append(l[2]), sentiment.append(0)\n",
    "                else:\n",
    "                    phID.append(l[0]), stcID.append(l[1]), ph.append(l[2]), sentiment.append(1)\n",
    "        else:\n",
    "            for line in f:\n",
    "                l = line.split(\"\\t\")\n",
    "                phID.append(l[0]), stcID.append(l[1]), ph.append(l[2])\n",
    "                \n",
    "    return np.array(phID).astype(int), np.array(stcID).astype(int), np.array(ph), np.array(sentiment).astype(int)\n",
    "\n",
    "#make validation dataset\n",
    "def split_train_test(data, percentage=80):\n",
    "    size = len(data)\n",
    "    indexes = np.arange(0,size)\n",
    "    np.random.shuffle(indexes)\n",
    "    \n",
    "    train_indexes = indexes[0:int(size*percentage/100)]\n",
    "    test_indexes = indexes[int(size*percentage/100):-1]\n",
    "    \n",
    "    return train_indexes, test_indexes\n",
    "    \n",
    "phraseID, sentenceID, sentences, sentiment = load_tsv(\"SKIM-RNN/train.tsv\")\n",
    "train_indexes, test_indexes = split_train_test(phraseID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module de preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Trim, Store, Count, Index words from dataset'''\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Preprocesser():\n",
    "    \n",
    "    '''main functions'''\n",
    "    def __init__(self,corpus):\n",
    "        '''corpus : np_array(string)'''\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "        self.corpus = corpus\n",
    "        self.size = len(corpus)\n",
    "    \n",
    "    # Lowercase, trim, and remove non-letter characters\n",
    "    # (no stop words in skim rnn ?)\n",
    "    def normalize(self):\n",
    "        new_corpus = np.array([])\n",
    "        steps,i = np.arange(0,self.size,self.size/10),0\n",
    "        for s in self.corpus:\n",
    "            uni_s = s.tostring().decode('unicode-escape')\n",
    "            uni_s = self.unicodeToAscii(uni_s.lower().strip())\n",
    "            uni_s = re.sub(r\"([.!?])\", r\" \\1\", uni_s)\n",
    "            uni_s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", uni_s)\n",
    "            new_corpus = np.append(new_corpus, uni_s)\n",
    "            if (i in steps):\n",
    "                print (\"...\")\n",
    "            i+=1\n",
    "        self.corpus = new_corpus\n",
    "\n",
    "\n",
    "    def addSentences(self):\n",
    "        for sentence in self.corpus:\n",
    "            self.addSentence(sentence)\n",
    "        \n",
    "    '''called within the module:'''\n",
    "    def unicodeToAscii(self,s):\n",
    "        return ''.join(\n",
    "            c for c in unicodedata.normalize('NFD', s)\n",
    "            if unicodedata.category(c) != 'Mn'\n",
    "        )\n",
    "\n",
    "        \n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "            \n",
    "    def save(self,filename):\n",
    "        pkl.dump(self.corpus,open(filename+\"_corpus.pkl\",'wb'))\n",
    "        pkl.dump(self.word2count,open(filename+\"_w2c.pkl\",'wb'))\n",
    "        pkl.dump(self.word2index,open(filename+\"_w2i.pkl\",'wb'))\n",
    "        pkl.dump(self.index2word,open(filename+\"_i2w.pkl\", 'wb'))\n",
    "    \n",
    "    def load(self, filename):\n",
    "        self.corpus = pkl.load(open(filename+\"_corpus.pkl\", 'rb'))\n",
    "        self.word2count = pkl.load(open(filename+\"_w2c.pkl\", 'rb'))\n",
    "        self.word2index = pkl.load(open(filename+\"_w2i.pkl\", 'rb'))\n",
    "        self.index2word = pkl.load(open(filename+\"_i2w.pkl\", 'rb'))\n",
    "        self.size = len(self.corpus)\n",
    "        self.n_words = len(self.word2count.keys())\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#preprocesser = Preprocesser(sentences)\n",
    "#preprocesser.normalize()\n",
    "#preprocesser.addSentences()\n",
    "\n",
    "#preprocesser.save(\"preprocessing_IMDB\")\n",
    "\n",
    "\n",
    "preprocesser = Preprocesser({})\n",
    "preprocesser.load(\"preprocessing_IMDB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modules RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''RNN module : embedding layer -> gru layer -> linear layer (for output classification) -> softmax'''\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size)\n",
    "        \n",
    "        self.h20 = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "            output = self.h20(output)\n",
    "            output = self.softmax(output.view(1,-1))\n",
    "            #lstm - > (input, (hidden,c <- ???) , cf pytorch doc, 'initial cell state')\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return Variable(torch.rand(1, 1, self.hidden_size))\n",
    "    \n",
    "    \n",
    "    \n",
    "class SkimRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, d, dprime, output_size, k  ):\n",
    "        super(SkimRNN, self).__init__()\n",
    "        self.softmax_p = nn.LogSoftmax()\n",
    "        #self.linear_p = nn.Linear(input_size+d, k)\n",
    "        self.linear_p = nn.Linear(input_size+d, k)\n",
    "        self.mainRNN = RNN(input_size, d, output_size)\n",
    "        self.smallRNN = RNN(input_size, dprime, output_size)\n",
    "\n",
    "        self.d = d\n",
    "        self.dprime = dprime\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        print 'SKIM RNN'\n",
    "        input = input.view(1, 1, -1)\n",
    "        p = self.softmax_p(self.linear_p(torch.cat( (input, hidden), 2)).view(1,-1))\n",
    "        q = p.exp().multinomial()\n",
    "        print q.data[0,0]\n",
    "        if q.data[0,0]==0:\n",
    "            print 'RNN principal'\n",
    "            #main RNN\n",
    "            output, hidden = self.mainRNN(input, hidden)\n",
    "        else:\n",
    "            print 'RNN secondaire'\n",
    "            #small RNN\n",
    "            \n",
    "            # ce n'est plus l'état caché entier qui passe dans le petit RNN, mais le slice sur les dprime premiers\n",
    "            # élements. Pas sûr de mon coup mais je vois pas comment ça peut marcher avec les dimensions si on a\n",
    "            # un état caché de taille d en entrée dans le petit RNN. \n",
    "            # hidden décomposé en h0 (dprime premiers éléments) et h1\n",
    "            \n",
    "            h0 = hidden.view(-1)[:self.dprime]\n",
    "            output, h0 = self.smallRNN(input, h0.view(1,1,-1))\n",
    "            h1 = hidden.view(-1)[self.dprime:]\n",
    "            hidden = torch.cat( (h0.view(1,1,-1), h1.view(1,1,-1)), 2)\n",
    "        return output, p, hidden\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return Variable(torch.rand(1, 1, self.d))\n",
    "    \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonctions pour la gestion des inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(data, n_words, neg_value=0):\n",
    "    \"\"\"\n",
    "    encode target en one-hot, si neg_value \n",
    "    vaut zéro, ou en -1/1, si neg_value vaut\n",
    "    -1 par exemple\n",
    "    \"\"\"\n",
    "    y_onehot = torch.FloatTensor(n_words)\n",
    "    y_onehot.zero_().add_(neg_value)\n",
    "    return y_onehot.scatter_(0, data, 1)\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    result = torch.LongTensor(indexes).view(-1, 1)\n",
    "    return result\n",
    "\n",
    "\n",
    "def makeInputTarget(lang, sentence, target, n_classes=2):\n",
    "    input_variable = variableFromSentence(lang, sentence)\n",
    "    if target >= n_classes:\n",
    "        print 'target not in range (0, #classes - 1)'\n",
    "        return -1\n",
    "    target_variable = Variable(torch.LongTensor([target]))\n",
    "    return (input_variable, target_variable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonctions pour l'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gumbel():\n",
    "    return -torch.log(-torch.log(torch.FloatTensor(2).uniform_()))\n",
    "\n",
    "def r(logp, g, temperature):\n",
    "    num = [torch.exp( (pi + gi)/temperature) for (pi,gi) in zip(logp,g)]\n",
    "    denum = torch.sum(torch.exp( (logp.data + g)/temperature))\n",
    "    return [n.data/denum for n in num]\n",
    "\n",
    "\n",
    "def train(preprocesser, input,target,rnn, optimizer, criterion, temperature=1.0, gamma=1.0):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "    input_length = input.size()[0]\n",
    "    logp = []\n",
    "    rp = []\n",
    "    loss = 0\n",
    "    \n",
    "    for t in range(input_length):\n",
    "        word_onehot = binarize(input[t], preprocesser.n_words)\n",
    "        output, p, hidden = rnn(Variable(word_onehot), hidden)\n",
    "        logp.append(p.data)\n",
    "        g = gumbel()    \n",
    "        rp.append(r(p,g,temperature))\n",
    "    \n",
    "        c = criterion(output.view(1,-1), target)\n",
    "\n",
    "        loss += criterion(output.view(1,-1), target).data * np.prod(rp[t])\n",
    "    logp_skim = [l[0,1] for l in logp]   #get logp probabibilites of skimming for each word\n",
    "    loss = Variable( loss +(gamma/input_length) * np.sum(logp_skim) )\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    return output ,loss.data[0]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparamètres + apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKIM RNN\n",
      "1\n",
      "RNN secondaire\n",
      "SKIM RNN\n",
      "1\n",
      "RNN secondaire\n",
      "SKIM RNN\n",
      "1\n",
      "RNN secondaire\n",
      "SKIM RNN\n",
      "0\n",
      "RNN principal\n",
      "SKIM RNN\n",
      "0\n",
      "RNN principal\n",
      "SKIM RNN\n",
      "1\n",
      "RNN secondaire\n",
      "SKIM RNN\n",
      "0\n",
      "RNN principal\n",
      "SKIM RNN\n",
      "0\n",
      "RNN principal\n",
      "SKIM RNN\n",
      "0\n",
      "RNN principal\n",
      "SKIM RNN\n",
      "1\n",
      "RNN secondaire\n",
      "SKIM RNN\n",
      "0\n",
      "RNN principal\n",
      "SKIM RNN\n",
      "0\n",
      "RNN principal\n",
      "SKIM RNN\n",
      "0\n",
      "RNN principal\n",
      "SKIM RNN\n",
      "0\n",
      "RNN principal\n",
      "SKIM RNN\n",
      "1\n",
      "RNN secondaire\n",
      "SKIM RNN\n",
      "0\n",
      "RNN principal\n",
      "SKIM RNN\n",
      "0\n",
      "RNN principal\n",
      "SKIM RNN\n",
      "0\n",
      "RNN principal\n",
      "SKIM RNN\n",
      "0\n",
      "RNN principal\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of variables tuple does not require grad",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-4b235b972786>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpreprocesser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmakeInputTarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocesser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocesser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-167-3d8ea5135253>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(preprocesser, input, target, rnn, optimizer, criterion, temperature, gamma)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mlogp_skim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlogp\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m#get logp probabibilites of skimming for each word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogp_skim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pierre/miniconda2/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pierre/miniconda2/lib/python2.7/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of variables tuple does not require grad"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "rnn =  SkimRNN(preprocesser.n_words, 128, 5, 2, 2)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(rnn.parameters(), lr=1e-2)\n",
    "epoch,mod = 0,10\n",
    "losses = []\n",
    "accs = []\n",
    "\n",
    "for i in train_indexes[2:10]:\n",
    "    \n",
    "    s,t =preprocesser.corpus[i], sentiment[i]\n",
    "    input,target =  makeInputTarget(preprocesser, s, t)\n",
    "    output, l = train(preprocesser,input,target,rnn,optimizer,criterion,1)\n",
    "    \n",
    "    losses.append(l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- embedded ? à supprimer ou à faire dans skim rnn plutôt que dans les RNN\n",
    "\n",
    "        supprimé pour le moment, mots transformés en one hot avant passage dans skim rnn (mais ce n'est pas mentionné dans le papier de procéder comme ça ..)\n",
    "        \n",
    "- debug petit RNN (hidden state vs GRU)\n",
    "\n",
    "        ok, cf comm dans le skim rnn\n",
    "        \n",
    "- mieux gérer one hot (mot courant)\n",
    "\n",
    "          ok\n",
    "          \n",
    "          \n",
    "- preprocessing fait façon tuto pytorch, cf GlOVe\n",
    "\n",
    "\n",
    "- debug backward error \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
