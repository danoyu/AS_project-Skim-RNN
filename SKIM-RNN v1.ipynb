{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importer donn√©es rotten tomatoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "\n",
    "import preprocesser\n",
    "import outils\n",
    "import modules\n",
    "    \n",
    "phraseID, sentenceID, sentences, sentiment = outils.load_tsv(\"../train.tsv\")\n",
    "train_indexes, test_indexes = outils.split_train_test(phraseID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module de preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonctions pour la gestion des inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lang = preprocesser.Preprocesser(sentences)\n",
    "#lang.normalize()\n",
    "#lang.addSentences()\n",
    "#lang.save(\"preprocessing_IMDB\")\n",
    "\n",
    "\n",
    "lang = preprocesser.Preprocesser({})\n",
    "lang.load(\"../../preprocessing_IMDB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonctions pour l'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-11.4325\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-16.5351\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-20.6538\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-18.9012\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-32.3169\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-913.0001\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-522.5339\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-2.1652\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-30.6347\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-4.6262\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-1.1638\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-11.7915\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-85.8136\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-160.4016\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-18.6583\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-7.3473\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-1115.2153\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-8.4648\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-143.5441\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-3.4231\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-9.7909\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-11.8245\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-5.4501\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-128.6861\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-21.3697\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-246.8347\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-8.2901\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-34.0650\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-56.0613\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-18.4734\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-165.9019\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-84.7059\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-8.7049\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-1.3118\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-79.0761\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-105.4290\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-26.9814\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-0.4803\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-0.8058\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-16.8309\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-121.3761\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-1.6443\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-56.6072\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-100.3779\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-1.3585\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-0.1130\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-155.2577\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-10.7919\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-3.4768\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "\n",
      "-633.7268\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def X(p,g,i,temperature):\n",
    "    return np.exp((p[i]+g[i])/temperature)\n",
    "\n",
    "#size parameters\n",
    "embedding_size = 512\n",
    "d = 200\n",
    "dprime = 20\n",
    "#modules\n",
    "embedder = nn.Embedding(lang.n_words,embedding_size)\n",
    "selector = modules.Selector(embedding_size+d)\n",
    "skim_rnn = modules.RNN(embedding_size,dprime,2)\n",
    "rnn = modules.RNN(embedding_size,d,2)\n",
    "#loss criteria and optimizers\n",
    "criterion = nn.NLLLoss()\n",
    "test_criterion = nn.L1Loss()\n",
    "optim_selector = optim.SGD(selector.parameters(), lr=1e-2)\n",
    "optim_rnn = optim.SGD([{'params':skim_rnn.parameters()},{'params':rnn.parameters()}], lr=1e-2)\n",
    "#other variables\n",
    "skimcount,count = 0,0\n",
    "temperature, gamma = 0.5,1\n",
    "logp_skim = []\n",
    "global_losses = []\n",
    "\n",
    "\n",
    "#training snippet\n",
    "for i in train_indexes[:200]:\n",
    "    loss, selector_loss= 0,0\n",
    "    #make the input and the target\n",
    "    sentence, target = lang.corpus[i], sentiment[i]\n",
    "    input, target = preprocesser.makeInputTarget(lang,sentence,target)\n",
    "    input_size = input.size()[0]\n",
    "    \n",
    "    #go through each word\n",
    "    for word in range(input_size):\n",
    "        optim_selector.zero_grad(), optim_rnn.zero_grad()\n",
    "        \n",
    "        x, hidden = Variable(input[word]), rnn.initHidden()\n",
    "        embedding = embedder(x).view(1,1,-1)\n",
    "        #go through the selector\n",
    "        x = torch.cat((embedding, hidden),2).view(1,-1)\n",
    "        p = selector(x)\n",
    "        logp_skim.append(p.data[0,1])     #skimming proba, for regularization purposes\n",
    "        q = torch.multinomial(p.exp())\n",
    "        choice = int(q.data[0,0])\n",
    "        \n",
    "        if choice == 0:\n",
    "            #go through the normal RNN\n",
    "            output, hidden = rnn(embedding, hidden)\n",
    "        \n",
    "        else:\n",
    "            #go through the skim rnn, which implies 'cutting' the hidden state,\n",
    "            #running through the neural network, and building the new hidden state.\n",
    "            h0 = hidden.view(-1)[:dprime]\n",
    "            output, h0 = skim_rnn(embedding, h0.view(1,1,-1))\n",
    "            h1 = hidden.view(-1)[dprime:]\n",
    "            hidden = torch.cat( (h0.view(1,1,-1), h1.view(1,1,-1)), 2)\n",
    "            skimcount +=1\n",
    "        count += 1\n",
    "        \n",
    "        #add to the current losses\n",
    "        loss += criterion(output,target)\n",
    "        r_word = torch.FloatTensor([outils.r(p, outils.gumbel(), temperature)[0].prod()])\n",
    "        #selector_loss += p.view(-1)[choice]*Variable(loss.data * r_word)\n",
    "        g = outils.gumbel()\n",
    "        if choice==0:\n",
    "            selector_loss += loss.data*( - X(p.view(-1).data,g,0,temperature) / ( (temperature*np.exp(p.view(-1).data[1]))*(X(p.view(-1).data,g,0,temperature) + X(p.view(-1).data,g,1,temperature))) )\n",
    "        else:\n",
    "            selector_loss += loss.data*( - X(p.view(-1).data,g,1,temperature) / ( (temperature*np.exp(p.view(-1).data[0]))*(X(p.view(-1).data,g,0,temperature) + X(p.view(-1).data,g,1,temperature))) )\n",
    "        \n",
    "    #final losses calculations, backwards, and gradient steps\n",
    "    loss.backward(retain_graph=True)\n",
    "    selector_loss = selector_loss + (gamma/input_size) * np.sum(logp_skim)\n",
    "    #selector_loss.backward()\n",
    "    \n",
    "    selector.linear.weight.data -= selector_loss*1e-2\n",
    "    optim_rnn.step()\n",
    "    #optim_selector.step()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if epoch%mod == 0:\n",
    "        global_losses.append((loss.data[0], selector_loss))\n",
    "        accs.append(accuracy())\n",
    "    \n",
    "    \n",
    "    '''debug prints\n",
    "    print '//////////////////'\n",
    "    test = selector.linear.weight\n",
    "    print selector.linear.weight\n",
    "    print skim_rnn.h20.weight\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-16.1031 -16.0559 -16.0741  ...  -16.1102 -16.0916 -16.0917\n",
      "-16.0661 -16.0424 -16.0574  ...  -16.0980 -16.1071 -16.1057\n",
      "[torch.FloatTensor of size 2x712]\n",
      "\n",
      "\n",
      "-40.1983\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Parameter containing:\n",
      "-20.1230 -20.0758 -20.0939  ...  -20.1301 -20.1114 -20.1116\n",
      "-20.0859 -20.0623 -20.0773  ...  -20.1178 -20.1269 -20.1255\n",
      "[torch.FloatTensor of size 2x712]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print selector.linear.weight.data\n",
    "print selector_loss\n",
    "\n",
    "\n",
    "\n",
    "selector.linear.weight.data += 1e-1*selector_loss\n",
    "\n",
    "print selector.linear.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparam√®tres + apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- step qui m√†j les param√®tres (backward graph?)\n",
    "          \n",
    "- inputs via glove\n",
    "\n",
    "\n",
    "- v√©rifier r√©sultats apr√®s apprentissage\n",
    "\n",
    "\n",
    "- faire des batchs\n",
    "\n",
    "\n",
    "- impl√©menter skim rnn avec option lstm\n",
    "\n",
    "\n",
    "- impl√©menter fonctions d'√©valuations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(indexes,preprocesser,embedder,selector,rnn):\n",
    "    acc = 0.0\n",
    "    for i in indexes:\n",
    "        s,t =preprocesser.corpus[i], sentiment[i]\n",
    "        input,target =  makeInputTarget(preprocesser, s, t)\n",
    "        input_length = input.size()[0]\n",
    "        \n",
    "        for word in range(input_length):\n",
    "            hidden = rnn.initHidden()\n",
    "            x = input[word]\n",
    "            output, p, hidden = rnn(Variable(x), hidden)  \n",
    "        if output.exp().multinomial().data[0,0] == target.data[0]:\n",
    "            acc += 1\n",
    "            \n",
    "    return 100*float(acc/len(indexes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
